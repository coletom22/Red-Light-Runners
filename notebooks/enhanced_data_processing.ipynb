{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Annotation with Prediction Assistant\n",
    "This notebook has the same capabilities as `data_processing.ipynb` except each frame is analyzed by a model and predictions are drawn onto the screen\n",
    "Key commands\n",
    "\n",
    "| Button | Description |\n",
    "|--------|-------------|\n",
    "| s | **Save** file w/ annotations |\n",
    "| a | Move image to `to_annotate` |\n",
    "| z | **Undo** most recent box |\n",
    "| L click | **Draw** box |\n",
    "| R click | **Highlight** boxes to delete |\n",
    "| r | **Remove** highlighted boxes |\n",
    "| 1 | Change light to **green** |\n",
    "| 2 | Change light to **red** |\n",
    "| 3 | Change light to **yellow** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for predictions\n",
    "curr_model = os.listdir(\"../models/current_assistant\")[0]\n",
    "model_path = f'../models/current_assistant/{curr_model}'\n",
    "model =  YOLO(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directories for retrieving, copying, or moving frames and videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video folders\n",
    "trimmed_video_dir = '../data/videos/trimmed'\n",
    "processed_video_dir = '../data/videos/processed'\n",
    "\n",
    "# Unprocessed frames\n",
    "frame_dir = '../data/images/frames'\n",
    "\n",
    "# Resized and annotated frames\n",
    "processed_dir = \"../data/images/processed\"\n",
    "\n",
    "# 1920x1080 original copies\n",
    "original_dir = \"../data/images/frames_original\"\n",
    "\n",
    "# Images to augment later\n",
    "augmenting_dir = \"../data/images/for_augmenting\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather screen information so that annotating data is a smoother experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import screeninfo\n",
    "\n",
    "# Get second monitor details\n",
    "monitors = screeninfo.get_monitors()\n",
    "\n",
    "# Two monitor setup\n",
    "if len(monitors) > 1:\n",
    "    second_monitor = monitors[1]\n",
    "    x_offset, y_offset = second_monitor.x, second_monitor.y\n",
    "    screen_width, screen_height = second_monitor.width, second_monitor.height\n",
    "\n",
    "# Default to primary monitor\n",
    "else:\n",
    "    x_offset, y_offset = 0, 0\n",
    "    screen_width, screen_height = monitors[0].width, monitors[0].height \n",
    "\n",
    "# 95% screen width and height\n",
    "window_width = int(screen_width * 0.95)\n",
    "window_height = int(screen_height * 0.95)\n",
    "\n",
    "# Center window\n",
    "window_x = x_offset + (screen_width - window_width) // 2\n",
    "window_y = y_offset + (screen_height - window_height) // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for **redrawing** and **editing** BBoxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exit labelling variable\n",
    "exit = False\n",
    "\n",
    "# Change model\n",
    "change_model = False\n",
    "\n",
    "# Standardized image width/height\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = 768, 448\n",
    "\n",
    "# Iterate over every n-th frame\n",
    "STEP = 1\n",
    "\n",
    "# Color mapping based on key presses\n",
    "color_mapping = {\n",
    "    ord(\"1\"): (0, 255, 0),   # Green\n",
    "    ord(\"2\"): (0, 0, 255),   # Red\n",
    "    ord(\"3\"): (0, 255, 255), # Yellow\n",
    "}\n",
    "\n",
    "# Label mapping based on colors\n",
    "label_mapping = {\n",
    "    (0, 255, 0): \"green_light\",\n",
    "    (0, 0, 255): \"red_light\",\n",
    "    (0, 255, 255): \"yellow_light\"\n",
    "}\n",
    "\n",
    "# Class mapping based on label (for YOLO format that uses int instead of str)\n",
    "class_mapping = {\n",
    "    \"green_light\": 1,\n",
    "    \"red_light\": 2,\n",
    "    \"yellow_light\": 3\n",
    "}\n",
    "\n",
    "dataset_size = utils.get_latest_dataset_size()\n",
    "\n",
    "if dataset_size is None:\n",
    "    dataset_size = int(max(len(os.listdir(processed_dir), 1)))\n",
    "\n",
    "print(dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code\n",
    "#### 1. Helper functions for redrawing and editing BBoxes\n",
    "#### 2. Iterate over available frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draws annotations onto copy of resized image then resets the cv2 frame (img_copy)\n",
    "def redraw_bbox(annotations):\n",
    "    global img, img_copy\n",
    "    img = resized_img.copy()  # reset to the resized image\n",
    "    for ann in annotations:\n",
    "        cv2.rectangle(img, (int(ann[\"x1\"]), int(ann[\"y1\"])), (int(ann[\"x2\"]), int(ann[\"y2\"])), ann[\"color_code\"], int(ann['thickness']))\n",
    "    img_copy = img.copy()\n",
    "\n",
    "# Based on mouse events, draws/deletes/edits BBoxes\n",
    "def edit_bbox(event, x, y, flags, params):\n",
    "\n",
    "    # right click to select the box the cursor is inside of\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        clickedBox = False\n",
    "        for i, ann in enumerate(annotations):\n",
    "            if x > min(ann['x1'], ann['x2']) and x < max(ann['x1'], ann['x2']) and y > min(ann['y1'], ann['y2']) and y < max(ann['y1'], ann['y2']):\n",
    "                print(annotations[i])\n",
    "                ann[\"thickness\"] = 2\n",
    "                redraw_bbox(annotations)\n",
    "                clickedBox = True\n",
    "\n",
    "        if not clickedBox:\n",
    "            utils.reset_selection(annotations)\n",
    "            redraw_bbox(annotations)\n",
    "\n",
    "    global ix, iy, drawing, img_copy, img, current_color\n",
    "\n",
    "    # Left clicking starts a drawing event if the user is not currently drawing\n",
    "    if event == cv2.EVENT_LBUTTONDOWN and not drawing:  \n",
    "        drawing = True # event status is drawing\n",
    "        ix, iy = x, y # anchor point for the first corner of the rectangle\n",
    "        img_copy = img.copy()  # reset copy when starting a new rectangle\n",
    "\n",
    "    # When the cursor is moving and we are in drawing status display adjusted size of rectangle based on cursor location\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and drawing:  \n",
    "        img_copy = img.copy()  # reset to avoid multiple overlapping rectangles\n",
    "        cv2.rectangle(img_copy, (ix, iy), (x, y), current_color, 1) # drawing rectangle from ix, iy to current cursor position\n",
    "\n",
    "    # Left click when we are already drawing places the rectangle where the cursor is located during the click\n",
    "    elif event == cv2.EVENT_LBUTTONDOWN and drawing:  \n",
    "        drawing = False # reset event status to not drawing\n",
    "        cv2.rectangle(img, (ix, iy), (x, y), current_color, 1)  # draw on final image\n",
    "        annotations.append({\n",
    "            \"x1\": min(ix, x),\n",
    "            \"x2\": max(ix, x),\n",
    "            \"y1\": min(iy, y),\n",
    "            \"y2\": max(iy, y),\n",
    "            \"color_code\": current_color,\n",
    "            \"color\": label_mapping[current_color],\n",
    "            \"class\": class_mapping[label_mapping[current_color]],\n",
    "            \"thickness\": 1\n",
    "        }) # appends a map of values needed for documentation min/max x and y coordinates, color codes, colors, and class\n",
    "        \n",
    "        redraw_bbox(annotations)  # for view consistency\n",
    "\n",
    "\n",
    "\n",
    "# Iterate over each file in the frame dir\n",
    "files = os.listdir(frame_dir)\n",
    "for i in range(0, len(files), 1):\n",
    "    \n",
    "    filename = files[i]\n",
    "\n",
    "    model_name = curr_model.split('.')[0]\n",
    "\n",
    "    # List to store dicts of annotations\n",
    "    annotations = []\n",
    "    if exit:\n",
    "        break\n",
    "\n",
    "    file_path = os.path.join(frame_dir, filename)\n",
    "\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "\n",
    "        # Prepare annotation file\n",
    "        img_filename = os.path.basename(file_path)\n",
    "        print(img_filename)\n",
    "        print(os.path.splitext(img_filename)[0])\n",
    "        text_filename = os.path.splitext(img_filename)[0] + \".txt\"\n",
    "\n",
    "        # Viewing annotation file\n",
    "        viewing_annotation_path = f\"../data/labels/viewing/viewing_{text_filename}\"\n",
    "        # Formatted annotation file\n",
    "        yolo_annotations_path = f'../data/labels/formatted/{text_filename}'\n",
    "\n",
    "\n",
    "        # Load image\n",
    "        original_img = cv2.imread(file_path)  # keep original image\n",
    "        if original_img is None:\n",
    "            raise FileNotFoundError(\"Image not found. Check the file path.\")\n",
    "        \n",
    "        # Resize the image to a uniform size\n",
    "        resized_img = cv2.resize(original_img, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "\n",
    "        # Initialize working images\n",
    "        img = resized_img.copy()   # Active drawing image\n",
    "        img_copy = img.copy()      # Image copy for real-time updates\n",
    "        result = model(resized_img, verbose=False)[0]\n",
    "\n",
    "        # tracking variables\n",
    "        pred_red = 0\n",
    "        pred_yellow = 0\n",
    "        pred_green = 0\n",
    "\n",
    "        # add predictions to annotations\n",
    "        for ann in result.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = ann\n",
    "            annotations.append({\n",
    "                \"x1\": int(min(x1, x2)),\n",
    "                \"x2\": int(max(x1, x2)),\n",
    "                \"y1\": int(min(y1, y2)),\n",
    "                \"y2\": int(max(y1, y2)),\n",
    "                \"color_code\": color_mapping[ord(str(int(class_id)))],\n",
    "                \"color\": result.names[int(class_id)],\n",
    "                \"class\": int(class_id),\n",
    "                \"thickness\": 1\n",
    "                }  \n",
    "            )\n",
    "            if result.names[int(class_id)] == 'red_light':\n",
    "                pred_red += 1\n",
    "            elif result.names[int(class_id)] == 'yellow_light':\n",
    "                pred_yellow += 1\n",
    "            elif result.names[int(class_id)] == 'green_light':\n",
    "                pred_green += 1\n",
    "            # draw BBox\n",
    "            cv2.rectangle(img_copy, (int(x1), int(y1)), (int(x2), int(y2)), color_mapping[ord(str(int(class_id)))], 1)\n",
    "\n",
    "        utils.update_annotation_data(model_name, img_filename, 'pred_red_light', pred_red)\n",
    "        utils.update_annotation_data(model_name, img_filename, 'pred_yellow_light', pred_yellow)\n",
    "        utils.update_annotation_data(model_name, img_filename, 'pred_green_light', pred_green)\n",
    "        # Anchor variables\n",
    "        ix, iy = -1, -1\n",
    "        drawing = False\n",
    "        current_color = (0, 255, 0)  # Default: Green\n",
    "\n",
    "\n",
    "\n",
    "        # Create window and set mouse callback\n",
    "        window_name = f\"Label Data: {filename}\"\n",
    "        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)  # Allow resizing\n",
    "        cv2.resizeWindow(window_name, window_width, window_height)  # Set to 95% of screen size\n",
    "        cv2.moveWindow(window_name, window_x, window_y)  # Center it on the second monitor\n",
    "        cv2.setMouseCallback(window_name, edit_bbox)\n",
    "\n",
    "        # Display loop\n",
    "        while True:\n",
    "            cv2.imshow(window_name, img_copy)  # Show dynamic updates\n",
    "            key = cv2.waitKey(10) & 0xFF\n",
    "            \n",
    "            # Press 'Esc' to exit\n",
    "            if key == 27:\n",
    "                exit = True\n",
    "                break\n",
    "            \n",
    "            # Press 's' to save annotations\n",
    "            elif key == ord(\"s\"):\n",
    "\n",
    "                # Open viewing text file, iterate over annotations and write to file\n",
    "                with open(viewing_annotation_path, 'w') as viewing_file:\n",
    "                    for annotation in annotations:\n",
    "                        viewing_file.write(f\"{annotation}\\n\")\n",
    "                print(f\"Viewing annotations saved to {viewing_annotation_path}\")\n",
    "                \n",
    "                # Convert annotations to yolo format\n",
    "                yolo_annotations = utils.viewing_to_yolo(annotations, IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "\n",
    "                # Open yolo text file, iterate over annotations and write to file\n",
    "                with open(yolo_annotations_path, 'w') as yolo_file:\n",
    "                    for yolo_ann in yolo_annotations:\n",
    "                        yolo_str = \" \".join(map(str, yolo_ann))  # Convert each item to string and join with commas\n",
    "                        yolo_file.write(f\"{yolo_str}\\n\")  # Write formatted string to file\n",
    "                print(f\"YOLO annotations saved to {yolo_annotations_path}\")\n",
    "\n",
    "\n",
    "                # Open processed_dir and write resized image to the directory\n",
    "                os.makedirs(processed_dir, exist_ok=True)\n",
    "                processed_path = os.path.join(processed_dir, os.path.basename(file_path))\n",
    "                cv2.imwrite(processed_path, resized_img)\n",
    "                print(f\"Moved {filename} -> {processed_path}\")\n",
    "\n",
    "                os.makedirs(original_dir, exist_ok=True)\n",
    "                original_path = os.path.join(original_dir, os.path.basename(file_path))\n",
    "                shutil.move(file_path, original_path)\n",
    "\n",
    "                utils.update_annotation_data(model_name, img_filename, 'total_annotations', len(annotations))\n",
    "\n",
    "                red_count = 0\n",
    "                yellow_count = 0\n",
    "                green_count = 0\n",
    "                \n",
    "                for ann in annotations:\n",
    "                    if ann['color'] == 'red_light':\n",
    "                        red_count += 1\n",
    "                    elif ann['color'] == 'yellow_light':\n",
    "                        yellow_count += 1\n",
    "                    elif ann['color'] == 'green_light':\n",
    "                        green_count += 1\n",
    "\n",
    "                utils.update_annotation_data(model_name, img_filename, 'red_light', red_count)\n",
    "                utils.update_annotation_data(model_name, img_filename, 'rmv_red_light', 0)\n",
    "                utils.update_annotation_data(model_name, img_filename, 'yellow_light', yellow_count)\n",
    "                utils.update_annotation_data(model_name, img_filename, 'rmv_yellow_light', 0)\n",
    "                utils.update_annotation_data(model_name, img_filename, 'green_light', green_count)\n",
    "                utils.update_annotation_data(model_name, img_filename, 'rmv_green_light', 0)\n",
    "                break\n",
    "\n",
    "\n",
    "            # Press 'a' to move frame to data/images/for_augmenting\n",
    "            elif key == ord('a'):\n",
    "                for_augmenting_path = os.path.join(augmenting_dir, os.path.basename(file_path))\n",
    "                shutil.move(file_path, for_augmenting_path)\n",
    "                print(f\"Moved {filename} -> {for_augmenting_path}\")\n",
    "                break\n",
    "                \n",
    "            # Change rectangle color based on number key\n",
    "            elif key in color_mapping:  \n",
    "                current_color = color_mapping[key]\n",
    "                print(f\"Class changed to: {label_mapping[color_mapping[key]]}\")\n",
    "            \n",
    "            # Press 'r' to remove bbox drawn by model assistant\n",
    "            elif key == ord(\"r\"):\n",
    "                utils.remove_bbox(annotations, model_name, img_filename)\n",
    "                redraw_bbox(annotations)\n",
    "                \n",
    "            # Press 'z' to undo last rectangle\n",
    "            elif key == ord(\"z\") and annotations: \n",
    "                annotations.pop()  # remove last rectangle\n",
    "                redraw_bbox(annotations)  # reset image and redraw remaining rectangles\n",
    "                print(\"Last rectangle removed!\")\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        # when the dataset has increased by 10% from the previous training\n",
    "        if len(os.listdir(processed_dir)) >= dataset_size * 1.1:\n",
    "\n",
    "            date_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")   # unique identifier for model\n",
    "            utils.train_assistant_model(date_time)                     # splits dataset and trains new model\n",
    "            utils.dump_data()                                          # places files back in original dir\n",
    "            utils.track_dataset(date_time, processed_dir)              # updates meta data file\n",
    "            dataset_size = utils.get_latest_dataset_size()             # update dataset size\n",
    "\n",
    "            # update new model as current assistant\n",
    "            curr_model = os.listdir(\"../models/current_assistant\")[0]\n",
    "            model_path = f'../models/current_assistant/{curr_model}'\n",
    "            model =  YOLO(model_path)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
